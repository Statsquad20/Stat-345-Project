---
title: "STAT 345 Final Project - Over and Over and Over and Over"
author: "STAT 345 "
output: html_document
---

Expected Submission: You will generate a well-written R Markdown report that addresses the following prompts. This R Markdown report should source your analysis code and only display top-level, abstracted code _if/when appropriate_. Choices made during the analysis project should be described and justified in the report. The written report (knitted file) and your analysis code should be submitted to Canvas by Tuesday, May 13 at 6:45pm. 

Advice for getting started:

- Start a conversation chain with your group members. Email is a great place to start, but other options exist (texting, social media platforms, etc.). Set some reasonable expectations for how and when you plan to respond to conversations. It is likely going to be unacceptable to only respond once per week, for example, but also likely unacceptable to expect a response within the hour. Have an honest conversation with your group members about this issue.
- Start the project from a "top-down design" perspective. So, determine what the major steps of the process are, and determine what the inputs and outputs are for each of those steps (the output of step 1 will likely be the input for step 2, for example). This step is much like writing an outline for a paper before you start to write the paper itself, only much more valuable in a group setting. 
- Once you have a sense of the big picture (the outline), determine some "due dates" for each step of the process. Work backwards from the final submission date, giving yourselves time to work on each of the parts as needed. Given the top-down design, you should be able to "divide and conquer" -- working on parts of the project that depend on earlier steps.
- Decide how you plan to share code with each other. Using Git and GitHub is a really good choice here. If not, perhaps some form of shared directory online. In a worst-case scenario, email could also work. 
- Be prepared to give Dr. Baumann (at least) weekly updates on your progress. Some of this can be done via email, but discuss with your group about times you are each available to meet online as well (in an office-hour-like setting). Feel free to request meetings with Dr. Baumann to get help.

**General advice:** Get started early. If you wait to the last minute, it will not go well. For this project, you may find yourself spending a reasonable amount of time _searching_ for help.

1. Your first task is to create a list of top songs, dating back to 1958 (when Billboard introduced it's Hot 100 yearly chart). You may want to start with just the yearly top song, but your work should be general enough to account for multiple songs per year. You may narrow your search to a particular genre if you like. You may use any website that provides this information, though you may try to find one that makes part 2 as simple as possible.

```{r}
#Webscrape billboard, 1950's. Ian - 11:00 AM, 4/17/20.
#install.packages("rvest")
#install.packages("tidyverse")
#install.packages("stringr")
library(tidyverse)
library(rvest)  
library(stringr)

y_50 <- c(1958:1959)
y_60 <- c(1960:1969)
y_70 <- c(1970:1979)
y_80 <- c(1980:1989)
y_90 <- c(1990:1999)
y_00 <- c(2000:2009)
y_10 <- c(2010:2019)
y_all <- c(y_50,y_60,y_70,y_80,y_90,y_00,y_10)
#Acts as a vector that we can use with 'sapply', and run it through the song pull function.
#NOTE: Can only get top 30, as billboard only recorded top 30 until 1956. So for the first 6 years, only 30 songs each.
#NOTE: Due to the songs being only 30 per year, I started at 1958. I'll do a small list for those 2 years however, so we can keep the decade organization.

#Purpose: gather artist and song name for each 'Top 100' list for each year
#Input: a vector of years
#Output: A matrix of the year, rank, artist, and songs
songs <- function(x) {
url <- paste0("http://billboardtop100of.com/",x,"-2/")
h <- read_html(url)
rank <- h %>% html_nodes("td:nth-child(1)") %>% html_text()
artists <- h %>% html_nodes("td:nth-child(2)") %>% html_text()
songs <- h %>% html_nodes("td~ td+ td") %>% html_text()
year <- rep(x,length(rank))
top <- cbind(year,rank,artists,songs)
}

list_50 <- lapply(y_50, songs)
#Gets a list containing each years' matrices
mat_50 <- do.call(rbind,list_50)
#Converts the list into one big matrix
df_50 <- data.frame(mat_50)
#Perfect!
```

```{r}
#Webscrape billboard, 1960's. Ian - 12:15 AM, 4/17/20.
#We could functionize it, as I do below, and pull from the list for each year.
#Or we do each decade as an individual chunk for error and loading purposes.

#Purpose: create a dataframe for an entire decade of top songs.
#Input: a vector of years
#Output: a dataframe consisting of the rank, year, artist, and song for the year.
decades <- function(x) {
list_s <- lapply(x, songs)
mat <- do.call(rbind,list_s)
df <- data.frame(mat)
}

all_decades <- lapply(y_all,decades)
all_decades
#Years 2013, 2015-2019 are slightly goofed up, may need to be done individually

## 4-18 Bri. I found out why those aren't working. The website offers them in lots of characters and not in a table/list form so R cannot read it in that way

#The reason I did not use music outfitter is because their node pulls both the artist and song, but we could possibly seperate them by "-"
```

```{r}
##4-18 Bri. I vote we don't use this one. It seems not as accurate and a much harder way to compile the data


#Music outfitter with string split at "-". Ian - 1:34 PM, 4/17/20.
#Purpose: gather artist and song name for each 'Top 100' list for each year
#Input: a vector of years
#Output: A matrix of the year, rank, artist, and songs
#songs <- function(x) {
url <- paste0("https://www.musicoutfitters.com/topsongs/1950.htm")
h <- read_html(url)
song_outfit <- h %>% html_nodes(".list-group-item a") %>% html_text() %>% str_split("-")
song_outfit
#}


```


2. For the top songs in part 1, gather some basic information: artist, title, year, genre (if appropriate), length, and other variables you think might be informative (sales figures, etc.).
```{r}
## Bri- What info do we need/want? We have artist and title and year. Any more? 
```


3. Find a lyric hosting service (such as www.azlyrics.com or www.songlyrics.com, though these aren't the only options) that provides full lyrics to songs. Ideally, the URLs for these songs follow a reproducible pattern. Write a function that can automatically capture these song lyrics for your top songs from part 1, and then gather the lyrics. Do your best to keep this function general, but you may need to write code for specific instances.
```{r}
## 4- 18 Bri. Working on making a function to read the lyrics in based off the dataframes made earlier
## I am not sure why I am getting this error? This should be grabbing it. I have tried it with just like self inputting into google. 


findLyrics <- function (artist,song)
{
  a <- str_extract(artist, "\\w+" )
  s <- str_extract(artist, "\\w+" )
  url <- paste0("https://www.azlyrics.com/lyrics/",tolower(a),"/",tolower(s),".html")
  h <- read_html(url)
  lyrics <- h %>% html_nodes("br+ div") %>% html_text()
 return(lyrics) 

}

findLyrics("Sam Smith" , "I'm Ready")


```


4. Create two measures of song repetitiveness. Write a function (or two) to measure song repetitiveness, and apply it to each of the songs from part 1. Suggestions for "repetitiveness" include (but are definitely not limited to): "Do songs repeat the same phrase frequently?" and "Do songs repeat their song title frequently"

5. Have songs become more repetitive over time? Summarize and visualize your repetitive measures from part 4. 

6. (If possible) Extend your work to more songs! Consider more questions, like "Does genre matter?".